# VideoToText
# RuBertOnlyVideo_Check.ipynb
## Описание кода
#### 1. **Модель и токенизатор**

- `model = AutoModelForSequenceClassification.from_pretrained("./saved_model")`: загружает предварительно обученную модель для классификации последовательностей из сохраненной директории `./saved_model`. Это модель на базе библиотеки `transformers`.
  
- `tokenizer = AutoTokenizer.from_pretrained("./saved_model")`: загружает токенизатор, связанный с моделью, из той же директории. Токенизатор используется для преобразования текста в формат, который понимает модель.

#### 2. **Устройство**

- `device = torch.device("cuda" if torch.cuda.is_available() else "cpu")`: определяет устройство для выполнения вычислений. Если доступен GPU, используется `cuda`, в противном случае — CPU.

#### 3. **Функция нормализации текста**

- `def normalize_text(text):`: функция для нормализации введенного текста. Она приводит текст к нижнему регистру, удаляет лишние пробелы и знаки препинания.
  
  Преобразования внутри функции:
  - `text.strip().lower()`: удаляет начальные и конечные пробелы, а также приводит текст к нижнему регистру.
  - `re.sub(r'\s+', ' ', text)`: удаляет избыточные пробелы, заменяя их на одинарный пробел.
  - `re.sub(r'[^\w\s]', '', text)`: удаляет любые символы, кроме букв и пробелов.

#### 4. **Токенизация**

- `encoding = tokenizer(normalized_text, return_tensors='pt', truncation=True, padding=True, max_length=256)`: токенизирует нормализованный текст, преобразуя его в тензоры PyTorch (опция `return_tensors='pt'`), с усечением (если текст слишком длинный) и добавлением паддинга (если текст слишком короткий). Максимальная длина текста ограничена 256 токенами.

- `encoding = {k: v.to(device) for k, v in encoding.items()}`: перемещает токенизированные данные на устройство (CPU или GPU), которое было определено ранее.

#### 5. **Предсказание**

- `with torch.no_grad():`: отключает автоматическое вычисление градиентов для экономии памяти и ускорения вычислений при выполнении предсказаний (не требуется при обучении модели).

- `outputs = model(**encoding)`: передает токенизированные данные в модель для выполнения предсказаний. Выходные данные (`outputs`) содержат логиты (сырые выходы нейронной сети).

- `probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)`: вычисляет вероятности на основе логитов с помощью функции softmax.

#### 6. **LabelEncoder (Кодировщик меток)**

- `label_encoder = LabelEncoder()`: создает объект `LabelEncoder`, который используется для преобразования меток (тегов) в числовые значения и обратно.
  
- `label_encoder.classes_ = np.load('./saved_model/label_encoder_classes.npy', allow_pickle=True)`: загружает метки, которые были использованы при обучении модели, из файла `label_encoder_classes.npy`. Этот файл содержит список классов (тегов), которые кодировались при обучении.

#### 7. **Вывод предсказаний**

- `probabilities, indices = torch.topk(probabilities, top_k, dim=1)`: выбирает `top_k` меток с самыми высокими вероятностями. В данном случае выбирается 5 наиболее вероятных тегов.

- Цикл вывода:
  ```python
  for prob, idx in zip(probabilities[0], indices[0]):
      tag = label_encoder.inverse_transform([idx.item()])[0]
      print(f"{tag}: {prob.item():.4f}")
  ```
  Этот цикл извлекает индексы предсказанных меток и преобразует их обратно в текстовые теги с помощью метода `inverse_transform()` из `LabelEncoder`. Затем выводит тег и его вероятность в формате `Тег: вероятность`.

#### 8. **Ввод данных**

- `title = input("Введите описание картинки в видео: ")`: пользователь вводит текстовое описание, которое будет использоваться для предсказания тегов.
# RuBertOnlyVideoTrain.ipynb
## Описание кода

1. **Модель и токенизатор**  
   - `model = AutoModelForSequenceClassification.from_pretrained("./saved_model")`: загружает предварительно обученную модель для классификации последовательностей из сохраненной директории `./saved_model`. Это модель на базе библиотеки `transformers`.
   - `tokenizer = AutoTokenizer.from_pretrained("./saved_model")`: загружает токенизатор, связанный с моделью, из той же директории. Токенизатор используется для преобразования текста в формат, который понимает модель.

2. **Устройство**  
   - `device = torch.device("cuda" if torch.cuda.is_available() else "cpu")`: определяет устройство для выполнения вычислений. Если доступен GPU, используется `cuda`, в противном случае — CPU.

3. **Функция нормализации текста**  
   - `def normalize_text(text)`: функция для нормализации введенного текста. Она приводит текст к нижнему регистру, удаляет лишние пробелы и знаки препинания.
     - `text.strip().lower()`: удаляет начальные и конечные пробелы, а также приводит текст к нижнему регистру.
     - `re.sub(r'\s+', ' ', text)`: удаляет избыточные пробелы, заменяя их на одинарный пробел.
     - `re.sub(r'[^\w\s]', '', text)`: удаляет любые символы, кроме букв и пробелов.

4. **Ввод данных**  
   - `title = input("Введите описание картинки в видео: ")`: пользователь вводит текстовое описание изображения или видео через командную строку. Этот текст передается в функцию нормализации.

5. **Токенизация текста**  
   - `encoding = tokenizer(normalized_text, return_tensors='pt', truncation=True, padding=True, max_length=256)`: нормализованный текст преобразуется в последовательность токенов с использованием токенизатора. Это подготавливает текст для дальнейшей обработки моделью, обеспечивая обрезку и добавление необходимых символов.

6. **Предсказание меток**  
   - `outputs = model(**encoding)`: модель делает предсказание на основе токенизированного текста, возвращая логиты (выходы до применения softmax).
   - `probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)`: применяется функция softmax, чтобы преобразовать логиты в вероятности для каждого из классов (тегов).

7. **Загрузка кодировщика меток**  
   - `label_encoder.classes_ = np.load('./saved_model/label_encoder_classes.npy', allow_pickle=True)`: загружается объект `LabelEncoder`, который был использован для кодирования меток во время обучения модели. Он преобразует числовые предсказания в текстовые теги.

8. **Вывод вероятностей для тегов**  
   - `probabilities, indices = torch.topk(probabilities, top_k, dim=1)`: извлекаются `top_k` (например, 5) наиболее вероятных тегов.
   - `tag = label_encoder.inverse_transform([idx.item()])[0]`: для каждого предсказанного индекса тегов (из числового формата) возвращается соответствующий текстовой тег.
   - Программа выводит теги с вероятностями для удобного анализа и интерпретации результатов.

# VideoToText_CSV.ipynb
## Описание кода

1. **Загрузка процессора и модели BLIP для описания изображений**
   - `processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")`: загружает процессор BLIP, который используется для предварительной обработки изображений перед подачей в модель.
   - `model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")`: загружает модель BLIP для генерации текстовых описаний изображений.

2. **Загрузка модели и токенизатора для перевода**
   - `translation_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ru")`: загружает модель для перевода текста с английского на русский.
   - `translation_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ru")`: загружает токенизатор, соответствующий модели перевода, для подготовки текста к переводу.

3. **Загрузка модели и токенизатора для суммаризации**
   - `summarization_model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')`: загружает модель BART для суммаризации текста.
   - `summarization_tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')`: загружает токенизатор, связанный с моделью BART, для предварительной обработки текста перед суммаризацией.

4. **Определение устройства**
   - `device = "cuda" if torch.cuda.is_available() else "cpu"`: определяет устройство для вычислений. Если доступен GPU, используется `cuda`, иначе используется CPU.

5. **Извлечение кадров из видео**
   - `def extract_frames(video_path, num_frames=16)`: функция для извлечения кадров из видео. Извлекает определенное количество кадров (по умолчанию 16) из видеофайла.

6. **Генерация описаний для кадров с помощью BLIP**
   - `def generate_captions(frames, processor, model, device)`: функция, которая использует процессор и модель BLIP для генерации текстовых описаний каждого кадра видео. Используются сгенерированные описания для всех кадров и сохраняются уникальные.

7. **Суммаризация текста**
   - `def summarize_text(text, summarization_tokenizer, summarization_model)`: функция для суммаризации текста с помощью модели BART. Текст токенизируется и передается модели, которая возвращает краткую версию текста.

8. **Перевод текста на русский язык**
   - `def translate_to_russian(caption, translation_tokenizer, translation_model)`: функция для перевода текста на русский язык. Текст передается через токенизатор модели MarianMT, которая возвращает переведенный результат.

9. **Обработка видео и генерация переводов**
   - `def process_videos_and_generate_translations(video_folder, output_csv_path, processor, model, summarization_model, translation_model, device)`: основная функция, которая обрабатывает все видео в папке, генерирует описания для кадров, суммирует текст, переводит его на русский язык и записывает результаты в CSV файл.

10. **Объединение данных**
    - Данные из файла с переведенными описаниями видео загружаются с помощью `summarized_df = pd.read_csv('video_captions_translations.csv')`.
    - Затем они объединяются с другими данными на основе столбца `video_id`, и результат сохраняется в новый файл `merged_data.csv`.

11. **Сохранение объединенного результата**
    - После объединения данных, нужные колонки (например, `video_id`, `translated_description`, `tags`) сохраняются в новый CSV файл для дальнейшего использования.


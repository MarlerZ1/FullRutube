{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdd7293-121b-47ea-8214-858197fde898",
   "metadata": {},
   "source": [
    "Импорт библиотек и установка устройства"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "802dcdd7-b4d9-4f0f-a080-de173684bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import ffmpeg\n",
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, \n",
    "    MarianMTModel, MarianTokenizer, \n",
    "    BartForConditionalGeneration, BartTokenizer, \n",
    "    BlipProcessor, BlipForConditionalGeneration\n",
    ")\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Выбор устройства для вычислений (GPU или CPU)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7699c1-0e95-4056-a974-2f4c9924affe",
   "metadata": {},
   "source": [
    "Загрузка моделей и токенизаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a944d2f5-d31f-4e1e-ae33-4b85b0efd6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Загрузка моделей и токенизаторов\n",
    "whisper_model = whisper.load_model(\"small\", device=device)  # Модель распознавания речи\n",
    "\n",
    "translation_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\").to(device)\n",
    "translation_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ru-en\")  # Модель и токенизатор для перевода с русского на английский\n",
    "\n",
    "back_translation_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-ru\").to(device)\n",
    "back_translation_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-ru\")  # Модель и токенизатор для перевода с английского на русский\n",
    "\n",
    "summarization_model_name = 'facebook/bart-large-cnn'\n",
    "summarization_model = BartForConditionalGeneration.from_pretrained(summarization_model_name).to(device)\n",
    "summarization_tokenizer = BartTokenizer.from_pretrained(summarization_model_name)  # Модель и токенизатор для суммаризации текста\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528fcac8-ec9b-41bc-be86-570c9ddbe8cd",
   "metadata": {},
   "source": [
    "Функция для нормализации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2dd7fc8-96a6-4c2a-9a43-7500fe8285b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Нормализация текста: удаление пробелов и нежелательных символов\"\"\"\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c108ac-bcb4-41f5-9e57-872e7a18d0a4",
   "metadata": {},
   "source": [
    "Обработка аудио"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd3a46a7-dba7-4c24-a081-336125ec4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(video_path):\n",
    "    \"\"\"Обработка аудио для RuBertAudio: транскрибация, перевод и суммаризация\"\"\"\n",
    "    temp_audio_path = \"temp_audio.wav\"\n",
    "    \n",
    "    try:\n",
    "        # Извлечение аудио из видео\n",
    "        ffmpeg.input(video_path, t=90).output(temp_audio_path, acodec='pcm_s16le', ac=1, ar='16000').run(quiet=True)\n",
    "    except ffmpeg.Error as e:\n",
    "        print(e.stderr.decode())\n",
    "        raise\n",
    "\n",
    "    # Транскрибация аудио\n",
    "    transcript = whisper_model.transcribe(temp_audio_path)\n",
    "    os.remove(temp_audio_path)\n",
    "\n",
    "    # Перевод на английский\n",
    "    english_text = translator_to_english(transcript['text'])\n",
    "    # Суммаризация\n",
    "    summary_english = summarize(english_text)\n",
    "    # Перевод обратно на русский\n",
    "    summarized_text = translate_to_russian(summary_english)\n",
    "\n",
    "    return summarized_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd8272-a718-4218-b650-bcc462bb2678",
   "metadata": {},
   "source": [
    "Функции перевода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79e7eee-a956-4fb4-aa32-35bd37163eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator_to_english(text):\n",
    "    \"\"\"Перевод текста с русского на английский\"\"\"\n",
    "    inputs = translation_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    translated = translation_model.generate(**inputs)\n",
    "    return translation_tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "def translate_to_russian(text):\n",
    "    \"\"\"Перевод текста с английского на русский\"\"\"\n",
    "    inputs = back_translation_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    translated_back = back_translation_model.generate(**inputs)\n",
    "    return back_translation_tokenizer.decode(translated_back[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec31b07-a121-4e28-98c8-87fadd98f69f",
   "metadata": {},
   "source": [
    "Суммаризация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a79a93f2-e5ca-4cf9-a6b2-8fc0aec997dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    \"\"\"Суммаризация текста\"\"\"\n",
    "    inputs = summarization_tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    summary_ids = summarization_model.generate(inputs['input_ids'], max_length=300, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    return summarization_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017c379-badd-45ea-bf15-7d4fcf66712b",
   "metadata": {},
   "source": [
    "Обработка видео кадров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d0532d-9fce-4085-bcc7-80ef5ce67914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_frames(video_path):\n",
    "    \"\"\"Обработка видео кадров и получение текстовых описаний\"\"\"\n",
    "    # Загрузка моделей для генерации описаний\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    caption_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "    caption_model.to(device)\n",
    "\n",
    "    # Извлечение и обработка кадров видео\n",
    "    frames = extract_frames(video_path)\n",
    "    captions = generate_captions(frames, processor, caption_model, device)\n",
    "    combined_text = \", \".join(captions)\n",
    "\n",
    "    # Суммаризация и перевод описаний\n",
    "    summarized_text = summarize(combined_text)\n",
    "    translated_description = translate_to_russian(summarized_text)\n",
    "\n",
    "    return translated_description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44310743-47fe-4893-8bfe-ecbbd9b2d8c8",
   "metadata": {},
   "source": [
    "Извлечение и обработка кадров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ba893c-9bf9-43fd-b6ee-351509d1a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=16):\n",
    "    \"\"\"Извлечение кадров из видео\"\"\"\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_interval = max(total_frames // num_frames, 1)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    while success and len(frames) < num_frames:\n",
    "        if count % frame_interval == 0:\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(Image.fromarray(image_rgb))\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "    vidcap.release()\n",
    "    return frames\n",
    "\n",
    "def generate_captions(frames, processor, model, device):\n",
    "    \"\"\"Генерация описаний для каждого из кадров\"\"\"\n",
    "    captions = []\n",
    "    unique_captions = set()\n",
    "    inputs = processor(images=frames, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_length=30, num_beams=5, early_stopping=True)\n",
    "    for output in outputs:\n",
    "        caption = processor.decode(output, skip_special_tokens=True)\n",
    "        if caption not in unique_captions:\n",
    "            unique_captions.add(caption)\n",
    "            captions.append(caption)\n",
    "    return captions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cc91af-b559-4f3a-b1f0-99eda73bd8d6",
   "metadata": {},
   "source": [
    "Предсказание тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f063264f-211c-41b7-9aa0-777260fe92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tags(model_path, input_text):\n",
    "    \"\"\"Предсказание тегов с использованием обученной модели\"\"\"\n",
    "    # Загрузка модели и токенизатора\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model.to(device)\n",
    "\n",
    "    # Нормализация и токенизация текста\n",
    "    normalized_text = normalize_text(input_text)\n",
    "    encoding = tokenizer(normalized_text, return_tensors='pt', truncation=True, padding=True, max_length=256)\n",
    "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
    "\n",
    "    # Предсказание\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Загрузка кодировщика меток\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.classes_ = np.load(os.path.join(model_path, 'label_encoder_classes.npy'), allow_pickle=True)\n",
    "\n",
    "    # Получение топовых тегов\n",
    "    top_k = 5\n",
    "    probabilities, indices = torch.topk(probabilities, top_k, dim=1)\n",
    "    tags_with_probs = [(label_encoder.inverse_transform([idx.item()])[0], prob.item()) for prob, idx in zip(probabilities[0], indices[0])]\n",
    "\n",
    "    return tags_with_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fbe913c-0e5f-47f9-95b1-a7f87e9b43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def combine_and_select_top_tags(text_tags, audio_tags, video_tags, top_n=5):\n",
    "    \"\"\"Объединение и выбор самых уверенных тегов от трех различных моделей, без повторений\"\"\"\n",
    "    \n",
    "    # Объединение всех тегов в один список\n",
    "    all_tags = text_tags + audio_tags + video_tags\n",
    "    \n",
    "    # Используем словарь для хранения максимальной уверенности для каждого тега\n",
    "    tag_confidence = defaultdict(lambda: 0)\n",
    "\n",
    "    # Обновляем словарь, сохраняя максимальную уверенность для каждого тега\n",
    "    for tag, accuracy in all_tags:\n",
    "        if accuracy > tag_confidence[tag]:\n",
    "            tag_confidence[tag] = accuracy\n",
    "\n",
    "    # Преобразуем в список и сортируем по убыванию уверенности\n",
    "    sorted_tags = sorted(tag_confidence.items(), key=lambda item: item[1], reverse=True)\n",
    "    \n",
    "    # Выбираем топ-N наиболее уверенных тегов\n",
    "    most_confident_tags = sorted_tags[:top_n]\n",
    "\n",
    "    # Выводим наиболее уверенные теги и их точность\n",
    "    print(\"Наиболее уверенные теги и их точность:\")\n",
    "    for tag, accuracy in most_confident_tags:\n",
    "        print(f\"{tag}: {accuracy:.2f}\")\n",
    "\n",
    "    return most_confident_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c142d0-878f-4a43-b1fe-67d83b2700c2",
   "metadata": {},
   "source": [
    "Основная логика выполнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8223f491-9b9b-4063-ac39-2394387c6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path, title, description):\n",
    "    \"\"\"Основная функция для обработки видео и получения тегов\"\"\"\n",
    "    \n",
    "    # Обработка текста\n",
    "    print(\"Processing text...\")\n",
    "    combined_text = f\"{title} {description}\"\n",
    "    text_tags = predict_tags(\"RuBertText/saved_model\", combined_text)\n",
    "    print(\"Text model tags:\", text_tags)\n",
    "\n",
    "    # Обработка аудио\n",
    "    print(\"Processing audio...\")\n",
    "    summarized_audio_text = process_audio(video_path)\n",
    "    audio_tags = predict_tags(\"RuBertAudio/saved_model\", summarized_audio_text)\n",
    "    print(\"Audio model tags:\", audio_tags)\n",
    "\n",
    "    # Обработка видео\n",
    "    print(\"Processing video frames...\")\n",
    "    translated_video_description = process_video_frames(video_path)\n",
    "    video_tags = predict_tags(\"RuBertVideo/saved_model\", translated_video_description)\n",
    "    print(\"Video model tags:\", video_tags)\n",
    "\n",
    "    # Объединяем результаты всех моделей\n",
    "    combine_and_select_top_tags(text_tags, audio_tags, video_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c09139-8bf4-4b1b-965f-e397eb7865f8",
   "metadata": {},
   "source": [
    "Запуск основного метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "057fd30b-edde-421a-9ad2-01e1ce28dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text...\n",
      "Text model tags: [(np.str_('Массовая культура: Юмор и сатира'), 0.5076751708984375), (np.str_('Массовая культура'), 0.2455354630947113), (np.str_('Еда и напитки: Кулинария'), 0.01389509066939354), (np.str_('Спорт: Рыбалка'), 0.008057245053350925), (np.str_('Путешествия'), 0.007944507524371147)]\n",
      "Processing audio...\n",
      "Audio model tags: [('Массовая культура: Юмор и сатира', 0.9809638261795044), ('Массовая культура', 0.0017407310660928488), ('Еда и напитки: Кулинария', 0.0014596988912671804), ('Образование: Онлайн-образование', 0.0010987541172653437), ('Религия и духовность: астрология', 0.0010873978026211262)]\n",
      "Processing video frames...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video model tags: [('Массовая культура', 0.6661799550056458), ('Массовая культура: Юмор и сатира', 0.12876959145069122), ('Транспорт', 0.02259010262787342), ('Путешествия', 0.014793174341320992), ('События и достопримечательности: Исторические места и достопримечательности', 0.007212325930595398)]\n",
      "Наиболее уверенные теги и их точность:\n",
      "Массовая культура: Юмор и сатира: 0.98\n",
      "Массовая культура: 0.67\n",
      "Транспорт: 0.02\n",
      "Путешествия: 0.01\n",
      "Еда и напитки: Кулинария: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "video_path = \"drift.mp4\"\n",
    "title = \"Название\"\n",
    "description = \"Описание\"\n",
    "main(video_path, title, description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5914c-1454-4ddb-b897-d1779ddd2e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
